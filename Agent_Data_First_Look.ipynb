{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Documentation for Thread Files : </h3>\n",
    "1. 8 threads running the simulation (agents) parallel. Each thread would write into it's own file (thread_i.txt) where i>=0 && i<8.\n",
    "\n",
    "2. The first line contains the total number of agents and ratio of Milli seconds to frames.  (Ex: 8501, 0.05). So in this example 1 frame = 20 milliseconds.\n",
    "\n",
    "3. The format of the other lines is: sec, agent_id, agent_type, has_luggage, is_disabled, X, Y, Z, velocity, queue_id, lookUp_X, lookUp_Y. (lookUp_X, lookUp_Y - gives the next position of the agent)\n",
    "\n",
    "4. Regarding the heights: For floor f, the Z = 3 * ( f -1 ) + 1. So for the first floor, Z=1, second Z= 4, third Z= 7 etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Major Things to Do </h3>\n",
    "\n",
    "- Map Entrance/Exit data onto Agent Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml # For reading building.yaml as a Python dict\n",
    "import ast\n",
    "\n",
    "from Buildings_Exploratory import df as entry_exit_points\n",
    "\n",
    "\n",
    "# Matplotlib Config\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.1\n",
      "1.12.1\n",
      "3.12\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__) # Should be 0.20.1\n",
    "print(np.__version__) # Should be 1.12.1\n",
    "print(yaml.__version__) # Should be 3.12 - If you don't have this use 'pip install pyyaml' into your command line/terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read thread_x file and convert to a PANDAS dataframe (and one CSV)\n",
    "### Column Names for our dataframe\n",
    "\n",
    "col_names = ['sec', \n",
    "             'agent_id',\n",
    "             'agent_type',\n",
    "             'has_luggage',\n",
    "             'is_disabled',\n",
    "             'X', \n",
    "             'Y',\n",
    "             'Z',\n",
    "             'velocity',\n",
    "             'queue_id',\n",
    "             'lookUp_X',\n",
    "             'lookUp_Y']\n",
    "\n",
    "# Convert the file into a Pandas DF. Ignore first line (header=0) and use col_names as headers instead.\n",
    "# Play around with this df and generalize the outcomes for the other 7 files\n",
    "\n",
    "df = pd.read_csv('Files/Agents/thread_0.txt', header=0, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for merging all 8 files into one big dataframe - Don't think this approach is correct\n",
    "# as each file (probably?) represents a seperate simulation.\n",
    "\n",
    "file_number = list(range(0,8))\n",
    "main_df = pd.DataFrame()\n",
    "\n",
    "### Iterate over the 8 files and add each individual files dataframe to one large df called main_df\n",
    "\n",
    "for i in file_number:\n",
    "    df_thread = pd.read_csv('Files/Agents/thread_' + str(i) + '.txt',header=0,names=col_names)\n",
    "    main_df = main_df.append(df_thread,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort dataframe by Agent_ID and TimeStamp\n",
    "#df = df.sort_values(by=['agent_id','sec'])\n",
    "#df.head(20)\n",
    "\n",
    "# Plot one agent\n",
    "#df[df['agent_id'] == 0].plot.scatter(x='X',y='Y',figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Z values to floors (don't know if useful or not)\n",
    "\n",
    "# Function to convert Z value to floor\n",
    "def z_to_floor(z_value):\n",
    "    return (z_value + 2) / 3\n",
    "\n",
    "#df['Z'] = df['Z'].map(lambda x : z_to_floor(x))\n",
    "#print(df['Z'].value_counts())\n",
    "\n",
    "# Not all Z values are integers. Are these agents between floors? On Elevators or Stairs or something?\n",
    "# If we use floor division instead of float division in the conversion function (i.e. use // instead of /), we'd\n",
    "# end up with integers but not sure how accurate that would be as it rounds down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Code for merging all 8 files into one big dataframe - Don't think this approach is correct\n",
    "# as each file (probably?) represents a seperate simulation.\n",
    "\n",
    "file_number = list(range(0,8))\n",
    "entry_df = pd.DataFrame()\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "### Iterate over the 8 files and add each individual files dataframe to one large df called main_df\n",
    "\n",
    "for i in file_number:\n",
    "    \n",
    "    df_thread = pd.read_csv('Files/Agents/thread_' + str(i) + '.txt',header=0,names=col_names)\n",
    "    df = df_thread.sort_values(\"sec\").groupby(\"agent_id\", as_index=False).first() \n",
    "    df_list = []\n",
    "    dist = 100\n",
    "\n",
    "    #calculating euclidean distance\n",
    "    for i in df.iterrows(): #each agent going into the loop\n",
    "        starting_point = (i[1]['X'],i[1]['Y'],(i[1]['Z']-1)) #there is a -1 on Z value to make it in unison with building Z values\n",
    "        for j in entry_exit_points.iterrows(): #each exit going into the loop\n",
    "            for k in j[1]['triangles']: #each triangle going into the loop\n",
    "                d = distance.euclidean(k,starting_point) #distance from each triangle to starting point of agent\n",
    "                if d < dist:\n",
    "                    dist = d\n",
    "                    entrance = j[1]['name']\n",
    "                    triangle = k\n",
    "\n",
    "        data = {'agent_id' : i[1]['agent_id'],\n",
    "                'entry_time' : i[1]['sec'],\n",
    "                'agent_type' : i[1]['agent_type'],\n",
    "                'has_luggage' :  i[1]['has_luggage'],\n",
    "                'is_disabled' : i[1]['is_disabled'],\n",
    "                'starting_point' : starting_point,\n",
    "                'entrance' : entrance,\n",
    "                'dist' : dist,\n",
    "                'triangle' : triangle}\n",
    "        df_list.append(data)\n",
    "\n",
    "    entrances = pd.DataFrame(df_list)\n",
    "    \n",
    "    entry_df = entry_df.append(entrances,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for merging all 8 files into one big dataframe - Don't think this approach is correct\n",
    "# as each file (probably?) represents a seperate simulation.\n",
    "\n",
    "file_number = list(range(0,8))\n",
    "\n",
    "exit_df = pd.DataFrame()\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "### Iterate over the 8 files and add each individual files dataframe to one large df called main_df\n",
    "\n",
    "for i in file_number:\n",
    "    \n",
    "    df_thread = pd.read_csv('Files/Agents/thread_' + str(i) + '.txt',header=0,names=col_names)\n",
    "    \n",
    "    # Fetch the last \n",
    "    df = df_thread.sort_values(\"sec\").groupby(\"agent_id\", as_index=False).last() \n",
    "    df_list = []\n",
    "    dist = 100\n",
    "\n",
    "    #calculating euclidean distance\n",
    "    for i in df.iterrows(): #each agent going into the loop\n",
    "        \n",
    "        starting_point = (i[1]['X'],i[1]['Y'],(i[1]['Z']-1)) #there is a -1 on Z value to make it in unison with building Z values\n",
    "        \n",
    "        for j in entry_exit_points.iterrows(): #each exit going into the loop\n",
    "            for k in j[1]['triangles']: #each triangle going into the loop\n",
    "                d = distance.euclidean(k,starting_point) #distance from each triangle to starting point of agent\n",
    "                if d < dist:\n",
    "                    dist = d\n",
    "                    exit = j[1]['name']\n",
    "                    triangle = k\n",
    "\n",
    "        data = {'agent_id' : i[1]['agent_id'],\n",
    "                'entry_time' : i[1]['sec'],\n",
    "                'agent_type' : i[1]['agent_type'],\n",
    "                'has_luggage' :  i[1]['has_luggage'],\n",
    "                'is_disabled' : i[1]['is_disabled'],\n",
    "                'starting_point' : starting_point,\n",
    "                'exits' : exit,\n",
    "                'dist' : dist,\n",
    "                'triangle' : triangle}\n",
    "        \n",
    "        df_list.append(data)\n",
    "\n",
    "    exits = pd.DataFrame(df_list)\n",
    "    \n",
    "    exit_df = exit_df.append(exits,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Agent_Data_First_Look.ipynb to script\n",
      "[NbConvertApp] Writing 6934 bytes to Agent_Data_First_Look.py\n"
     ]
    }
   ],
   "source": [
    "#!jupyter nbconvert --to script Agent_Data_First_Look.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
